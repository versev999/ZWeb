"""
å›¾åƒç”ŸæˆæœåŠ¡å±‚
æ”¯æŒæœ¬åœ°æ¨¡å‹å’Œè¿œç¨‹APIä¸¤ç§è°ƒç”¨æ–¹å¼
"""

import base64
import httpx
import asyncio
import io
from pathlib import Path
from typing import Optional
from datetime import datetime
from abc import ABC, abstractmethod

from config import get_config


class ImageGenerationResult:
    """å›¾åƒç”Ÿæˆç»“æœ"""
    
    def __init__(
        self,
        success: bool,
        image_data: Optional[bytes] = None,
        image_base64: Optional[str] = None,
        file_path: Optional[str] = None,
        error: Optional[str] = None,
        generation_time: float = 0.0
    ):
        self.success = success
        self.image_data = image_data
        self.image_base64 = image_base64
        self.file_path = file_path
        self.error = error
        self.generation_time = generation_time
    
    def to_dict(self) -> dict:
        return {
            "success": self.success,
            "image_base64": self.image_base64,
            "file_path": self.file_path,
            "error": self.error,
            "generation_time": self.generation_time
        }


class BaseImageGenerator(ABC):
    """å›¾åƒç”Ÿæˆå™¨åŸºç±»"""
    
    @abstractmethod
    async def generate(
        self,
        prompt: str,
        negative_prompt: str = "",
        width: int = 512,
        height: int = 512,
        steps: int = 20,
        guidance_scale: float = 7.5,
        seed: Optional[int] = None
    ) -> ImageGenerationResult:
        """ç”Ÿæˆå›¾åƒ"""
        pass


class LocalModelGenerator(BaseImageGenerator):
    """æœ¬åœ°æ¨¡å‹å›¾åƒç”Ÿæˆå™¨"""
    
    def __init__(self, model_path: str, device: str = "cuda", enable_optimizations: bool = True):
        self.model_path = model_path
        self.device = device
        self.enable_optimizations = enable_optimizations
        self._model = None
        self._pipe = None
    
    def _load_model(self):
        """åŠ è½½æœ¬åœ°æ¨¡å‹"""
        if self._pipe is not None:
            return
        
        try:
            import torch
            from diffusers import DiffusionPipeline
            
            print(f"\n{'='*60}")
            print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {self.model_path}")
            print(f"ç›®æ ‡è®¾å¤‡: {self.device}")
            
            # æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨
            model_path = Path(self.model_path)
            if not model_path.exists():
                raise FileNotFoundError(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {self.model_path}")
            
            # æ£€æŸ¥è®¾å¤‡å¯ç”¨æ€§
            if self.device == "cuda" and not torch.cuda.is_available():
                print("âš ï¸  è­¦å‘Š: CUDAä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPUæ¨¡å¼")
                self.device = "cpu"
            elif self.device == "cuda":
                print(f"âœ… æ£€æµ‹åˆ° GPU: {torch.cuda.get_device_name(0)}")
                print(f"   æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
            
            # åŠ è½½æ¨¡å‹
            print("ğŸ“¦ æ­£åœ¨åŠ è½½æ¨¡å‹æ–‡ä»¶...")
            
            # å°è¯•åŠ è½½VAEï¼ˆå¦‚æœå­˜åœ¨å•ç‹¬çš„VAEï¼‰
            vae = None
            try:
                from diffusers import AutoencoderKL
                vae_path = model_path / "vae"
                if vae_path.exists():
                    print("ğŸ“¦ æ£€æµ‹åˆ°ç‹¬ç«‹VAEï¼Œæ­£åœ¨åŠ è½½...")
                    vae = AutoencoderKL.from_pretrained(
                        str(vae_path),
                        torch_dtype=torch.float32,  # VAEä½¿ç”¨float32é¿å…NaN
                    )
                    print("âœ… VAEåŠ è½½æˆåŠŸ (float32)")
            except Exception as e:
                print(f"â„¹ï¸  æœªåŠ è½½ç‹¬ç«‹VAE: {e}")
            
            # åŠ è½½ä¸»æ¨¡å‹
            # Z-Imageæ¨¡å‹éœ€è¦ä½¿ç”¨float32é¿å…NaNé»‘å›¾é—®é¢˜
            load_kwargs = {
                "torch_dtype": torch.float32,
                "use_safetensors": True,
            }
            
            # å¦‚æœæœ‰ç‹¬ç«‹VAEï¼Œä½¿ç”¨å®ƒ
            if vae is not None:
                load_kwargs["vae"] = vae
            
            self._pipe = DiffusionPipeline.from_pretrained(
                self.model_path,
                **load_kwargs
            )
            
            print("â„¹ï¸  ä½¿ç”¨ float32 ç²¾åº¦ï¼ˆZ-Imageæ¨¡å‹è¦æ±‚ï¼‰")
            
            # ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
            print(f"ğŸš€ æ­£åœ¨å°†æ¨¡å‹ç§»åŠ¨åˆ° {self.device}...")
            self._pipe = self._pipe.to(self.device)
            
            # æ£€æŸ¥æ¨¡å‹ç»„ä»¶
            print(f"ğŸ“‹ æ¨¡å‹ç»„ä»¶:")
            if hasattr(self._pipe, 'vae'):
                print(f"   âœ… VAE: {type(self._pipe.vae).__name__} ({self._pipe.vae.dtype})")
            if hasattr(self._pipe, 'transformer'):
                print(f"   âœ… Transformer: {type(self._pipe.transformer).__name__} ({self._pipe.transformer.dtype})")
            elif hasattr(self._pipe, 'unet'):
                print(f"   âœ… UNet: {type(self._pipe.unet).__name__} ({self._pipe.unet.dtype})")
            if hasattr(self._pipe, 'text_encoder'):
                print(f"   âœ… Text Encoder: {type(self._pipe.text_encoder).__name__}")
            
            # åº”ç”¨ä¼˜åŒ–
            if self.device == "cuda" and self.enable_optimizations:
                self._apply_optimizations()
            
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ!")
            print(f"{'='*60}\n")
            
        except ImportError as e:
            raise ImportError(
                f"âŒ ç¼ºå°‘å¿…è¦çš„ä¾èµ–åº“ã€‚\n"
                f"è¯·å®‰è£…: uv pip install torch diffusers transformers accelerate\n"
                f"é”™è¯¯è¯¦æƒ…: {e}"
            )
        except FileNotFoundError as e:
            raise FileNotFoundError(f"âŒ {e}")
        except Exception as e:
            raise RuntimeError(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    def _apply_optimizations(self):
        """åº”ç”¨å„ç§æ¨ç†ä¼˜åŒ–"""
        import torch
        
        print(f"\nğŸš€ åº”ç”¨æ¨ç†ä¼˜åŒ–:")
        optimizations_applied = []
        
        # 1. Attention Slicing - é™ä½å†…å­˜å ç”¨
        try:
            self._pipe.enable_attention_slicing(slice_size="auto")
            optimizations_applied.append("âœ… Attention Slicing")
        except Exception as e:
            print(f"   âš ï¸  Attention Slicing å¤±è´¥: {e}")
        
        # 2. xformers - å†…å­˜é«˜æ•ˆçš„æ³¨æ„åŠ›æœºåˆ¶
        try:
            self._pipe.enable_xformers_memory_efficient_attention()
            optimizations_applied.append("âœ… xformers å†…å­˜ä¼˜åŒ–")
        except Exception as e:
            optimizations_applied.append("â„¹ï¸  xformers ä¸å¯ç”¨")
        
        # 3. VAE Slicing - é™ä½VAEè§£ç çš„å†…å­˜å ç”¨
        try:
            if hasattr(self._pipe, 'enable_vae_slicing'):
                self._pipe.enable_vae_slicing()
                optimizations_applied.append("âœ… VAE Slicing")
        except Exception:
            pass
        
        # 4. VAE Tiling - å¤„ç†å¤§å›¾åƒæ—¶åˆ†å—è§£ç 
        try:
            if hasattr(self._pipe, 'enable_vae_tiling'):
                self._pipe.enable_vae_tiling()
                optimizations_applied.append("âœ… VAE Tiling")
        except Exception:
            pass
        
        # 5. Torch Compile (PyTorch 2.0+) - æœ€å¼ºåŠ é€Ÿ
        # æ³¨æ„: Z-Imageæ¨¡å‹çš„RoPEå®ç°ä¸torch.compileä¸å…¼å®¹ï¼Œæš‚æ—¶ç¦ç”¨
        # å¦‚æœæ˜¯æ ‡å‡†çš„Stable Diffusionæ¨¡å‹ï¼Œå¯ä»¥å¯ç”¨æ­¤ä¼˜åŒ–
        if False and torch.__version__ >= "2.0.0":
            try:
                # ç¼–è¯‘ UNet/Transformer ä»¥è·å¾—æœ€å¤§åŠ é€Ÿ
                if hasattr(self._pipe, 'transformer'):
                    self._pipe.transformer = torch.compile(
                        self._pipe.transformer,
                        mode="reduce-overhead",
                        fullgraph=True
                    )
                    optimizations_applied.append("âœ… Torch Compile (Transformer)")
                elif hasattr(self._pipe, 'unet'):
                    self._pipe.unet = torch.compile(
                        self._pipe.unet,
                        mode="reduce-overhead",
                        fullgraph=True
                    )
                    optimizations_applied.append("âœ… Torch Compile (UNet)")
            except Exception as e:
                optimizations_applied.append(f"â„¹ï¸  Torch Compile è·³è¿‡: {str(e)[:50]}")
        
        # 6. CUDAä¼˜åŒ–
        try:
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            torch.backends.cudnn.benchmark = True
            optimizations_applied.append("âœ… CUDA TF32 + cuDNN Benchmark")
        except Exception:
            pass
        
        # è¾“å‡ºä¼˜åŒ–ç»“æœ
        for opt in optimizations_applied:
            print(f"   {opt}")
        print()
    
    async def generate(
        self,
        prompt: str,
        negative_prompt: str = "",
        width: int = 512,
        height: int = 512,
        steps: int = 20,
        guidance_scale: float = 7.5,
        seed: Optional[int] = None
    ) -> ImageGenerationResult:
        """ä½¿ç”¨æœ¬åœ°æ¨¡å‹ç”Ÿæˆå›¾åƒ"""
        import time
        import io
        import torch
        
        start_time = time.time()
        
        try:
            # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
            self._load_model()
            
            # è®¾ç½®éšæœºç§å­
            generator = None
            if seed is not None:
                generator = torch.Generator(device=self.device).manual_seed(seed)
            
            # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œæ¨¡å‹æ¨ç†ï¼ˆé¿å…é˜»å¡å¼‚æ­¥äº‹ä»¶å¾ªç¯ï¼‰
            loop = asyncio.get_event_loop()
            image = await loop.run_in_executor(
                None,
                self._generate_sync,
                prompt,
                negative_prompt,
                width,
                height,
                steps,
                guidance_scale,
                generator
            )
            
            # å°†PILå›¾åƒè½¬æ¢ä¸ºå­—èŠ‚
            img_byte_arr = io.BytesIO()
            image.save(img_byte_arr, format='PNG')
            image_bytes = img_byte_arr.getvalue()
            
            # è½¬æ¢ä¸ºbase64
            image_base64 = base64.b64encode(image_bytes).decode("utf-8")
            
            generation_time = time.time() - start_time
            
            return ImageGenerationResult(
                success=True,
                image_data=image_bytes,
                image_base64=image_base64,
                generation_time=generation_time
            )
        except Exception as e:
            return ImageGenerationResult(
                success=False,
                error=f"å›¾åƒç”Ÿæˆå¤±è´¥: {str(e)}",
                generation_time=time.time() - start_time
            )
    
    def _generate_sync(
        self,
        prompt: str,
        negative_prompt: str,
        width: int,
        height: int,
        steps: int,
        guidance_scale: float,
        generator
    ):
        """åŒæ­¥ç”Ÿæˆå›¾åƒï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰"""
        import numpy as np
        from PIL import Image
        
        # ç”Ÿæˆå›¾åƒï¼ˆè¾“å‡ºnumpyæ•°ç»„ï¼‰
        result = self._pipe(
            prompt=prompt,
            negative_prompt=negative_prompt,
            width=width,
            height=height,
            num_inference_steps=steps,
            guidance_scale=guidance_scale,
            generator=generator,
            output_type="np",
        )
        
        # è·å–numpyæ•°ç»„
        images_np = result.images
        
        # æ£€æŸ¥å¼‚å¸¸å€¼ï¼ˆè°ƒè¯•ç”¨ï¼‰
        if np.isnan(images_np).any() or np.isinf(images_np).any():
            print("âš ï¸  è­¦å‘Š: æ£€æµ‹åˆ°NaNæˆ–Infå€¼ï¼Œæ­£åœ¨æ¸…ç†...")
            images_np = np.nan_to_num(images_np, nan=0.0, posinf=1.0, neginf=0.0)
        
        # ç¡®ä¿å€¼åœ¨ [0, 1] èŒƒå›´å†…
        images_np = np.clip(images_np, 0, 1)
        
        # è½¬æ¢ä¸ºPILå›¾åƒ
        image_np = images_np[0]  # å–ç¬¬ä¸€å¼ å›¾åƒ
        image_uint8 = (image_np * 255).round().astype(np.uint8)
        
        # åˆ›å»ºPILå›¾åƒ
        if image_uint8.shape[-1] == 3:
            image = Image.fromarray(image_uint8, mode='RGB')
        else:
            image = Image.fromarray(image_uint8.squeeze(), mode='L')
        
        return image


class RemoteAPIGenerator(BaseImageGenerator):
    """è¿œç¨‹APIå›¾åƒç”Ÿæˆå™¨"""
    
    def __init__(self, endpoint: str, api_key: str):
        self.endpoint = endpoint
        self.api_key = api_key
    
    async def generate(
        self,
        prompt: str,
        negative_prompt: str = "",
        width: int = 512,
        height: int = 512,
        steps: int = 20,
        guidance_scale: float = 7.5,
        seed: Optional[int] = None
    ) -> ImageGenerationResult:
        """é€šè¿‡è¿œç¨‹APIç”Ÿæˆå›¾åƒ"""
        import time
        start_time = time.time()
        
        try:
            async with httpx.AsyncClient(timeout=120.0) as client:
                headers = {
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                }
                
                payload = {
                    "prompt": prompt,
                    "negative_prompt": negative_prompt,
                    "width": width,
                    "height": height,
                    "steps": steps,
                    "guidance_scale": guidance_scale,
                }
                
                if seed is not None:
                    payload["seed"] = seed
                
                response = await client.post(
                    self.endpoint,
                    headers=headers,
                    json=payload
                )
                
                if response.status_code == 200:
                    result = response.json()
                    # å‡è®¾APIè¿”å› base64 ç¼–ç çš„å›¾åƒ
                    image_base64 = result.get("image", result.get("data", ""))
                    
                    return ImageGenerationResult(
                        success=True,
                        image_base64=image_base64,
                        generation_time=time.time() - start_time
                    )
                else:
                    return ImageGenerationResult(
                        success=False,
                        error=f"APIé”™è¯¯: {response.status_code} - {response.text}",
                        generation_time=time.time() - start_time
                    )
                    
        except httpx.TimeoutException:
            return ImageGenerationResult(
                success=False,
                error="è¯·æ±‚è¶…æ—¶",
                generation_time=time.time() - start_time
            )
        except Exception as e:
            return ImageGenerationResult(
                success=False,
                error=str(e),
                generation_time=time.time() - start_time
            )


class ImageService:
    """å›¾åƒç”ŸæˆæœåŠ¡"""
    
    def __init__(self):
        self.config = get_config()
        self._generators: dict[str, BaseImageGenerator] = {}
    
    def _get_generator(self, model_id: str) -> BaseImageGenerator:
        """è·å–æˆ–åˆ›å»ºå›¾åƒç”Ÿæˆå™¨"""
        if model_id not in self._generators:
            model_config = self.config.get_model_config(model_id)
            if not model_config:
                raise ValueError(f"æœªæ‰¾åˆ°æ¨¡å‹é…ç½®: {model_id}")
            
            model_type = model_config.get("type", "")
            
            if model_type == "local":
                self._generators[model_id] = LocalModelGenerator(
                    model_path=model_config.get("model_path", ""),
                    device=model_config.get("device", "cuda"),
                    enable_optimizations=model_config.get("enable_optimizations", True)
                )
            elif model_type == "remote":
                self._generators[model_id] = RemoteAPIGenerator(
                    endpoint=model_config.get("endpoint", ""),
                    api_key=model_config.get("api_key", "")
                )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹: {model_type}")
        
        return self._generators[model_id]
    
    async def generate_image(
        self,
        prompt: str,
        model_id: Optional[str] = None,
        negative_prompt: str = "",
        width: Optional[int] = None,
        height: Optional[int] = None,
        steps: Optional[int] = None,
        guidance_scale: Optional[float] = None,
        seed: Optional[int] = None,
        save_to_file: bool = False
    ) -> ImageGenerationResult:
        """ç”Ÿæˆå›¾åƒ"""
        # ä½¿ç”¨é»˜è®¤æ¨¡å‹
        if not model_id:
            model_id = self.config.default_model
        
        # è·å–æ¨¡å‹é…ç½®
        model_config = self.config.get_model_config(model_id)
        if not model_config:
            return ImageGenerationResult(
                success=False,
                error=f"æœªæ‰¾åˆ°æ¨¡å‹: {model_id}"
            )
        
        # ä½¿ç”¨æ¨¡å‹é»˜è®¤å‚æ•°å¡«å……ç¼ºå¤±å‚æ•°
        default_params = model_config.get("default_params", {})
        width = width or default_params.get("width", 512)
        height = height or default_params.get("height", 512)
        steps = steps or default_params.get("steps", 20)
        guidance_scale = guidance_scale or default_params.get("guidance_scale", 7.5)
        
        # è·å–ç”Ÿæˆå™¨å¹¶ç”Ÿæˆå›¾åƒ
        generator = self._get_generator(model_id)
        result = await generator.generate(
            prompt=prompt,
            negative_prompt=negative_prompt,
            width=width,
            height=height,
            steps=steps,
            guidance_scale=guidance_scale,
            seed=seed
        )
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        if save_to_file and result.success and result.image_data:
            file_path = self._save_image(result.image_data)
            result.file_path = file_path
        
        return result
    
    def _save_image(self, image_data: bytes) -> str:
        """ä¿å­˜å›¾åƒåˆ°æ–‡ä»¶"""
        output_config = self.config.output
        save_dir = Path(output_config.save_dir)
        save_dir.mkdir(parents=True, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        filename = f"generated_{timestamp}.{output_config.format}"
        file_path = save_dir / filename
        
        with open(file_path, "wb") as f:
            f.write(image_data)
        
        return str(file_path)


# å…¨å±€æœåŠ¡å®ä¾‹
_service: Optional[ImageService] = None


def get_image_service() -> ImageService:
    """è·å–å›¾åƒæœåŠ¡å®ä¾‹"""
    global _service
    if _service is None:
        _service = ImageService()
    return _service
